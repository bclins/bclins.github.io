<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Math &amp; Society Notes</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="../mockup.css" />
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
  <meta http-equiv="Pragma" content="no-cache" />
  <meta http-equiv="Expires" content="0" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Math &amp; Society Notes</h1>
</header>
<h2 id="math-111---summer-2024">Math 111 - Summer 2024</h2>
<p>Quick Links: <a href="index.html">Syllabus</a></p>
<center>
<table class='bordered'>
<thead>
<tr>
<th>
Week
</th>
<th>
Mon
</th>
<th>
Tue
</th>
<th>
Wed
</th>
<th>
Thu
</th>
<th>
Fri
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
1
</td>
<td>
</td>
<td>
<a href="#day-1-notes">Day 1</a>
</td>
<td>
<a href="#day-2-notes">Day 2</a>
</td>
<td>
<a href="#day-3-notes">Day 3</a>
</td>
<td>
<a href="#day-4-notes">Day 4</a>
</td>
</tr>
<tr>
<td>
2
</td>
<td>
</td>
<td>
<a href="#day-5-notes">Day 5</a>
</td>
<td>
<a href="#day-6-notes">Day 6</a>
</td>
<td>
<a href="#day-7-notes">Day 7</a>
</td>
<td>
<a href="#day-8-notes">Day 8</a>
</td>
</tr>
<tr>
<td>
3
</td>
<td>
<a href="#day-9-notes">Day 9</a>
<td>
<a href="#day-10-notes">Day 10</a>
</td>
<td>
<a href="#day-11-notes">Day 11</a>
</td>
<td>
<a href="#day-12-notes">Day 12</a>
</td>
<td>
<a href="#day-13-notes">Day 13</a>
</td>
</tr>
<tr>
<td>
4
</td>
<td>
<a href="#day-14-notes">Day 14</a>
<td>
<a href="#day-15-notes">Day 15</a>
</td>
<td>
<a href="#day-16-notes">Day 16</a>
</td>
<td>
<a href="#day-17-notes">Day 17</a>
</td>
<td>
<a href="#day-18-notes">Day 18</a>
</td>
</tr>
<tr>
<td>
2
</td>
<td>
<a href="#day-19-notes">Day 19</a>
</td>
<td>
<a href="#day-20-notes">Day 20</a>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
</tr>
</tbody>
</table>
</center>
<h3 id="day-1-notes">Day 1 Notes</h3>
<h4 id="tue-may-21">Tue, May 21</h4>
<p>Today we introduced voting methods. See these slides for details.</p>
<ul>
<li><strong>Slides:</strong> <a href="day1slides.html">Introduction to Voting Theory</a></li>
</ul>
<p>We also did these two workshops in class.</p>
<ul>
<li><p><strong>Workshop:</strong> <a href="Workshops/InstantRunoff.pdf">Plurality &amp; Instant Run-Off Voting</a></p></li>
<li><p><strong>Workshop:</strong> <a href="Workshops/BordaCount.pdf">Borda Count</a></p></li>
</ul>
<h3 id="day-2-notes">Day 2 Notes</h3>
<p>Today we talked about fairness criteria that voting methods should have.</p>
<ul>
<li><strong>Slides:</strong> <a href="day2slides.html">Fairness Criteria</a></li>
</ul>
<p>We also did this workshop in class.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/FairnessCriteria.pdf">Fairness Criteria</a></li>
</ul>
<p>In addition to the slides &amp; workshop, we also talked about (and proved) the <a href="https://en.wikipedia.org/wiki/Median_voter_theorem">Median Voter Theorem</a>. We finished by talking about recent advocacy to promote ranked choice voting (another name for IRV) and STAR voting (which will not be on the test).</p>
<ul>
<li><strong>Video:</strong> <a href="https://youtu.be/3-mOeUXAkV0">STAR Voting</a></li>
</ul>
<p>It is something to pay attention to in the future, because there will always be a push for better voting methods than plurality voting.</p>
<h3 id="day-3-notes">Day 3 Notes</h3>
<p>Today we talked about <strong>weighted voting systems</strong>. We did this workshop:</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/BanzhafPower.pdf">Banzhaf power</a></li>
</ul>
<p>Before the workshop, we started with this example. Suppose a school is run by a committee with the principal who has 3 votes, the vice principal who has 2 votes, and three teachers who each have 1 votes. A motion requires 5 votes to pass.</p>
<p>We can use the shorthand notation [5: 3, 2, 1, 1, 1] to represent this weighted voting system. The first number is the vote <strong>threshold</strong> needed to pass a motion, and the other numbers are the <strong>weights</strong> which are the number of votes controlled by each voter. Often the voters in a weighted voting system are called <strong>players</strong>.</p>
<p>A <strong>winning coalition</strong> is a subset of the players who have enough votes to pass a motion. A player is <strong>critical</strong> in a winning coalition if the coalition would not have enough votes without that player.</p>
<ol type="1">
<li><p>List the winning coalitions in the weighted voting system above.</p></li>
<li><p>Circle the critical players in each winning coalition.</p></li>
</ol>
<p>The <strong>Banzhaf power index</strong> is a way to measure how much power each player in a weighted voting system has.</p>
<section id="banzhaf-power-index" class="Theorem">
<h4>Banzhaf Power Index</h4>
<p>To find the Banzhaf power for each player,</p>
<ol type="1">
<li>List the winning coalitions and circle the critical players in each coalition.</li>
<li>The power for each player is the fraction: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mtext mathvariant="normal">Number of times the player is circled</mtext><mtext mathvariant="normal">Total number of circles</mtext></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">\frac{\text{Number of times the player is circled}}{\text{Total number of circles}}.</annotation></semantics></math></li>
</ol>
</section>
<ol start="3" type="1">
<li>Calculate the Banzhaf power indices for the principal, vice principal, and each teacher in the example above.</li>
</ol>
<p><a href="">John Banzhaf</a> was a lawyer in the 1960s who discovered the power index when he was investigating a case involving Nassua County, NY. The districts in Nassau county had a weighted voting system where the weights were:</p>
<ul>
<li>Hempstead 1 had 9 votes</li>
<li>Hempstead 2 had 9 votes</li>
<li>North Hempstead had 7 votes</li>
<li>Oyster Bay had 3 votes</li>
<li>Glen Cove had 1 vote</li>
<li>Long Beach had 1 vote</li>
</ul>
<p>To reach the threshold of 16 votes to pass a motion, it required at least two of the bigger districts. But it never mattered what the three smaller districts did. So the three smaller districts had no power in the elections.</p>
<p>A player with no power is called a <strong>dummy</strong>. A player with enough power to pass a motion all by themselves is called a <strong>dictator</strong>. Sometimes a player can block any motion by themselves. Then we say they have <strong>veto power.</strong></p>
<ol start="4" type="1">
<li>Can you come up with a weighted voting system <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">[</mo><mi>t</mi><mo>:</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><msub><mi>p</mi><mn>2</mn></msub><mo>,</mo><msub><mi>p</mi><mn>3</mn></msub><mo>,</mo><msub><mi>p</mi><mn>4</mn></msub><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">[t : p_1, p_2, p_3, p_4]</annotation></semantics></math> where all four players have veto power?</li>
</ol>
<p>Banzhaf power can illustrate some surprising things about weighted voting systems. For example, the weights might be very different from the real amount of power each player has.</p>
<ol start="5" type="1">
<li>Suppose a country has a parliament with 200 seats. The seats are divided between three parties that always vote together as blocs. The red party has 99 seats, the blue party has 98 seats, and the green party has 3 seats. Surprisingly when you calculate the Banzhaf power, the green party has the same amount of power as the red and blue parties even though it has much fewer seats.</li>
</ol>
<p>Sometimes you can calculate the Banzhaf power indices without having any numbers for the weights and threshold. We did the following example.</p>
<ol start="6" type="1">
<li>At one college, promotion decisions are made by a committee of four faculty and the dean. The four faculty each vote, and if there is a tie, then the dean is the tie breaker. Calculate the Banzhaf power for each faculty member and for the dean.</li>
</ol>
<p>If you want to play with more weighted voting examples, Professor Koether made a <a href="https://people.hsc.edu/faculty-staff/robbk/Math111/Power/">Banzhaf power calculator</a> which you can try.</p>
<h3 id="day-4-notes">Day 4 Notes</h3>
<p>Today we talked about <strong>the spherical Earth theory</strong>. Actually, we talked about solving <strong>proportion equations</strong>, but most of the examples we did were related to the fact that the Earth is a sphere. We also talked about the evidence the ancient Greeks used to deduce that the Earth is a sphere.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/EratosthenesEarth.pdf">Eratosthenes measures the Earth</a></li>
</ul>
<p>After that, we talked about using the same ideas to find Latitude &amp; Longitude.</p>
<ul>
<li><strong>Slides:</strong> <a href="https://people.hsc.edu/faculty-staff/blins/classes/fall10/math111/LongitudePresentation.pdf">Longitude presentation</a></li>
</ul>
<p>We finished by talking about a useful technique to solve word problems involving unit conversions called <strong>factor-label method</strong>, also known as <strong>dimensional analysis</strong>. Here is a <a href="https://youtu.be/d_WfCwJW0Og">video explaining the technique</a> (I didnâ€™t make the video, but it is a pretty good explanation.</p>
<p>We did this example in class:</p>
<ol type="1">
<li>The international space station ISS orbits the Earth every 90 minutes. The orbit of the space station is 250 miles above the Earthâ€™s surface. How fast does the ISS move in miles per hour?</li>
</ol>
<p>Then we finished with this workshop:</p>
<ul>
<li><strong>Workshops:</strong> <a href="Workshops/FactorsUnits.pdf">Factors &amp; Units</a></li>
</ul>
<h3 id="day-5-notes">Day 5 Notes</h3>
<p>Today we talked about orders of magnitude. For any number, its <strong>order of magnitude</strong> is the exponent of the nearest power of 10. For example, 783 is closest to 1,000 which is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>10</mn><mn>3</mn></msup><annotation encoding="application/x-tex">10^3</annotation></semantics></math>, so the order of magnitude of 783 is 3. We also briefly reviewed <strong>scientific notation</strong> and the <strong>metric system</strong>. We did this workshop.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/OrdersOfMagnitude.pdf">Orders of Magnitude</a></li>
</ul>
<p>After that, we talked about <strong>logarithmic scales</strong> which are number lines where the numbers are spaced so that each step represents multiplication/division instead of addition/subtraction. We did this workshop</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/LogScale.pdf">Logarithmic Scales</a></li>
</ul>
<p>We also looked at examples where log-scales are used to present data. Sometimes these examples can be misleading. But sometimes a log-scale is the best way to represent the data.</p>
<ul>
<li><strong>Example:</strong>
<center>
<img src="covidLogScale.png" width=720></img>
</center></li>
<li><strong>Example:</strong>
<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/0/00/Moore%27s_Law_Transistor_Count_1970-2020.png" width=520></img>
</center></li>
</ul>
<p>Using log-scales to present data has advantages:</p>
<ol type="1">
<li><p>It spreads out small numbers so you can see them.</p></li>
<li><p>It lets you use one graph to represent numbers that are spread over many orders of magnitude.</p></li>
</ol>
<p>The disadvantages are:</p>
<ol type="1">
<li><p>It bunches up the big numbers, so it can make big differences seem small.</p></li>
<li><p>They are more confusing because not everyone is familiar with log-scales.</p></li>
</ol>
<h3 id="day-6-notes">Day 6 Notes</h3>
<p>We started by talking briefly about how the halfway point between two numbers on a logarithmic scale is not what you would expect. For example, the halfway point between 1 and 100 is 10, not 50. On a logarithmic scale, the halfway point between any two numbers <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math> is the <strong>geometric mean</strong> which is: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mrow><mi>x</mi><mi>y</mi></mrow></msqrt><mi>.</mi></mrow><annotation encoding="application/x-tex">\sqrt{xy}.</annotation></semantics></math><br />
The regular average where you add two numbers and then divide by 2 is called the <strong>arithmetic mean</strong>.</p>
<ol type="1">
<li>Find the geometric mean of 3 and 12. Compare it with the arithmetic mean. Which is bigger?</li>
</ol>
<p><strong>Fact.</strong> The arithmetic mean of two different positive numbers is always bigger than the geometric mean.</p>
<p>After we talked about arithmetic &amp; geometric means, we introduced growth factors. When any quantity increases (or decreases), the <strong>growth factor</strong> is defined to be <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Growth factor</mtext><mo>=</mo><mfrac><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> new amount </mtext><mspace width="0.333em"></mspace></mrow><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> old amount </mtext><mspace width="0.333em"></mspace></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">\text{Growth factor} = \frac{\text{ new amount }}{\text{ old amount }}.</annotation></semantics></math></p>
<ol start="2" type="1">
<li>Find the growth factor for the US population which increased from 282 million in 2000 to 330 million in 2020.</li>
</ol>
<p>Growth factors will be smaller than one if the quantity is decreasing.</p>
<ol start="3" type="1">
<li>In the aughts (2000-2009) there were 3962 murders in Virginia. In the teens (2010-2019) there were 3859 murders. Find the growth factor.</li>
</ol>
<p>When we work with growth factors that are close to one, we usually talk about percent change. <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">Growth factor</mtext><mo>=</mo><mn>100</mn><mi>%</mi><mo>+</mo><mtext mathvariant="normal">Percent Change</mtext><mi>.</mi></mrow><annotation encoding="application/x-tex">\text{Growth factor} = 100\% + \text{Percent Change}.</annotation></semantics></math></p>
<ol start="4" type="1">
<li>Find the percent change for the last two growth factors.</li>
</ol>
<p>Percent changes are confusing because you canâ€™t add and subtract percent changes. But you can multiply growth factors.</p>
<ol start="5" type="1">
<li>Suppose the population of a town grows by 10% one year, 20% the next year, and 30% the third year. How much has the population grown?</li>
</ol>
<p>We did these two workshops.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/RelativeGrowth.pdf">Relative growth</a></li>
</ul>
<p>After the break we talked about arithmetic and geometric sequences. An <strong>arithmetic sequence</strong> is a list of numbers that change by adding or subtracting a constant step size. A <strong>geometric sequence</strong> is a list of numbers that change by multiplying or dividing a constant factor, called the <strong>common ratio</strong>. <strong>Linear growth (or decrease)</strong> is when an arithmetic sequence is growing (or decreasing). <strong>Exponential growth (or decay)</strong> is when a geometric sequence is growing or decreasing.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/ExponentialGrowth.pdf">Exponential growth</a></li>
</ul>
<p>We finished by watching this video about exponential growth and the rule of 70.</p>
<ul>
<li><strong>Video:</strong> <a href="https://youtu.be/F-QA2rkpBSY">The Most IMPORTANT Video Youâ€™ll Ever See</a></li>
</ul>
<h3 id="day-7-notes">Day 7 Notes</h3>
<p>We started with a workshop.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/CompoundInterest.pdf">Compound interest</a></li>
</ul>
<p>Then we talked about <strong>logarithms</strong>. We talked about how (base-10) logarithms are pretty much the same thing as orders of magnitude. They tell you the exact location of a number on a logarithmic scale where each order of magnitude is one step.</p>
<p>Logarithms were discovered/invented by John Napier in the early 1600â€™s to help make arithmetic easier. Here is some of the history.</p>
<ul>
<li><p>1614 John Napier published the book <em>A Description of the Wonderful Rule of Logarithms</em>.</p></li>
<li><p>1617 Henry Briggs published the first base-10 logarithm tables.</p></li>
<li><p>1624 Edmund Wingate published <em>The Use of Rules of Proportion</em>. A <strong>rule of proportion</strong> is a wooden ruler with numbers marked on a logarithmic scale. Wingate got the idea from Edmund Gunter and these rulers were sometimes called <a href="https://www.nzeldes.com/HOC/images/Gunter02.jpg">Gunter sticks</a>.</p></li>
<li><p>Early 1630â€™s William Oughtred put two wooden rules of proportion together the make the first <a href="https://www.npr.org/sections/ed/2014/10/22/356937347/the-slide-rule-a-computing-device-that-put-a-man-on-the-moon">slide rule</a>.</p></li>
</ul>
<p>The reason that logarithms caught on so quickly is that they really did make peopleâ€™s lives a lot easier.</p>
<ol type="1">
<li>Suppose you had to calculate the area of a circle using the formula <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ï€</mi><msup><mi>r</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\pi r^2</annotation></semantics></math>. If you measure the radius to be 12.3 centimeters, then you would have to calculate <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">(</mo><mn>3.14</mn><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mn>12.3</mn><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="prefix">(</mo><mn>12.3</mn><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(3.14)(12.3)(12.3)</annotation></semantics></math> Thatâ€™s pretty hard without a calculator. With a table of logarithms, you can look up the logarithms of each number and then add them together which is much easier!</li>
</ol>
<h3 id="day-9-notes">Day 9 Notes</h3>
<p>Today we talked about the <strong>apportionment problem</strong>.</p>
<ul>
<li><strong>Slides:</strong> <a href="day9slides.html">The Apportionment Problem</a></li>
</ul>
<p>We also did this workshop</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/Hamilton.pdf">Hamiltonâ€™s method</a></li>
</ul>
<p>We also did an example where a Mom has 50 pieces of candy to give out to her 5 kids based on the number of minutes they spent doing chores.</p>
<center>
<table class="bordered">
<tr>
<td>
Alvin
</td>
<td>
Betty
</td>
<td>
Calvin
</td>
<td>
Daisy
</td>
<td>
Edwin
</td>
<td>
Total
</td>
</tr>
<tr>
<td>
150
</td>
<td>
78
</td>
<td>
173
</td>
<td>
204
</td>
<td>
295
</td>
<td>
900
</td>
</tr>
</table>
</center>
<ol type="1">
<li><p>What is the standard divisor? What are its units?</p></li>
<li><p>What is the standard quota for each kid?</p></li>
<li><p>What is the apportionment using Hamiltonâ€™s method.</p></li>
</ol>
<p>We finished by using a spreadsheet to find the apportionment of candy above using Jeffersonâ€™s method. We also used Jeffersonâ€™s method to find the final apportionment of Congress after George Washington vetoed the Apportionment Act of 1792.</p>
<h3 id="day-10-notes">Day 10 Notes</h3>
<p>Today we talked about advantages and disadvantages of the various apportionment methods. We also introduce the <strong>Huntington-Hill Method</strong> which is the one that the United States has used since 1941.</p>
<ul>
<li><strong>Slides:</strong> <a href="day10slides.html">The Apportionment Problem 2</a></li>
</ul>
<p>We did two workshops, the first involved using spreadsheets to implement divisor methods. You need to download the data file to do problem 2.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/JeffersonAdams.pdf">Jefferson &amp; Adams Methods</a></li>
<li><strong>Data:</strong> <a href="2020census.xlsx">2020census.xlsx</a></li>
</ul>
<p>The other was a quick example of using a logarithmic scale to implement the Huntington-Hill method.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/HuntingtonHill.pdf">Divisor Methods &amp; Logarithmic Scales</a></li>
</ul>
<h3 id="day-11-notes">Day 11 Notes</h3>
<p>Today we introduced <strong>graph theory</strong>. We started by verifying <strong>Eulerâ€™s formula</strong> which says that any graph on a piece of paper with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math> vertices, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>E</mi><annotation encoding="application/x-tex">E</annotation></semantics></math> edges, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>F</mi><annotation encoding="application/x-tex">F</annotation></semantics></math> faces or regions (including the one exterior face which is not enclosed by edges), the following formula is <em>always</em> true: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>+</mo><mi>F</mi><mo>âˆ’</mo><mi>E</mi><mo>=</mo><mn>2</mn><mi>.</mi></mrow><annotation encoding="application/x-tex"> V + F - E = 2.</annotation></semantics></math></p>
<p>A <strong>graph</strong> is a set of points called <strong>vertices</strong> and a set of lines connecting two vertices called <strong>edges</strong> (the edges donâ€™t have to be straight). A graph that you can draw on a piece of paper so that no edges cross (except at vertices) is called a <strong>planar graph</strong>.</p>
<p>According to legend, the subject of graph theory was discovered/invented in 1735 when Leonhard Euler heard about the Seven Bridges of KÃ¶nigsberg puzzle. At the time, KÃ¶nigsberg was a city in Prussia with seven bridges. The puzzle asks whether it is possible to walk around the city crossing every bridge exactly once. Assume that you can only cross the river by walking across on of the bridges.</p>
<center>
<img src="Konigsberg.jpg"></img>
</center>
<p>Euler solved the problem by abstracting away the irrelevant details and focusing on the underlying graph structure. A graph has an <strong>Euler path</strong> if there is a path that starts and ends at different vertices and crossed every edge exactly once. A graph has an <strong>Euler circuit</strong> if there is a path that starts and ends in the same place and crosses every edge exactly once.</p>
<center>
<img src="konigsbergGraph.png"></img>
</center>
<p>Euler figured out that the only thing that matters (as long as the graph is connected) is the degrees of the vertices in the graph. The <strong>degree</strong> of a vertex is the number of edges that touch it.</p>
<div class="Theorem">
<p><strong>Theorem.</strong> A connected graph has an Euler path if and only if it has exactly two vertices with an odd degree. A connected graph has an Euler circuit if and only if all of the degrees are even.</p>
</div>
<p>We didnâ€™t prove this theorem, but we did give an intuitive explanation for why it is true. Cole also had an interesting idea that maybe you have to have an even number of edges to have an Euler path, but we ended up finding some counter examples for that conjecture.</p>
<p>We also proved this handy theorem:</p>
<div class="Theorem">
<p><strong>The Handshake Theorem.</strong> In any graph, the sum of the degrees of all the vertices is twice the number of edges.</p>
</div>
<p>Then we did this workshop.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/EulerPaths.pdf">Euler paths</a></li>
</ul>
<p>We also talked about Flueryâ€™s algorithm, which is a way to find an Euler path (or circuit) in a graph.</p>
<div class="Theorem">
<p><strong>Flueryâ€™s algorithm.</strong> For a graph that has an Euler circuit (or path):</p>
<ol type="1">
<li><p>Pick a start vertex (must have odd degree if you are looking for a path).</p></li>
<li><p>Move along the graph from vertex to vertex, removing the edges you cross as you go. When you have a choice, never pick an edge that would make it impossible to reach some un-visited edges.</p></li>
<li><p>Continue until you are done.</p></li>
</ol>
</div>
<p>It is not obvious, but this algorithm always works as long as a graph is connected and has only even degree vertices (or just two odd degree vertices).</p>
<h3 id="day-12-notes">Day 12 Notes</h3>
<p>Today we talked about trees. A <strong>tree</strong> is a graph that is connected and has no cycles. A <strong>path</strong> is a sequence of adjacent edges with no repeats. A <strong>cycle</strong> is a path of length more than 1 that never repeats an edges and starts and ends at the same vertex. We proved these theorems about trees, the most important of which is this first one (which includes several of the other theorems).</p>
<div class="Theorem">
<p><strong>Tree Classification Theorem.</strong> For connected graphs, the following properties are equivalent. If a connected graph has one of these properties, then it has all of them.</p>
<ol type="1">
<li>The graph is a tree.</li>
<li>For any two points, there is only one (simple) path connecting them.<br />
</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>E</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V = E+1</annotation></semantics></math>.</li>
</ol>
</div>
<p>The first part of the proof is to show that properties 1 and 2 are equivalent. We called this Tree Theorem 1. Here is why it is true. If there were two paths, then eventually they would split and then rejoin. The edges between where the paths split and rejoin would form a cycle, which is impossible. Conversely if there were a cycle, then there would be more than one path connecting any two vertices in the cycle (one going clockwise, the other counterclockwise).</p>
<p>To prove that property 3 is equivalent to the other two properties in the Tree Classification Theorem takes a little more work. We needed some helper theorems. The first theorem is about <strong>leaves</strong> which are vertices with degree one in a tree.</p>
<div class="Theorem">
<p><strong>Theorem.</strong> Every tree with more than 1 vertex must have some leaves.</p>
</div>
<p>To prove this theorem, start from any vertex and make a path. Keep extending the path as long as you can, until you canâ€™t go any farther. There are only two reasons you canâ€™t go farther. Either you are at a dead end (which means you have found a degree one vertex), or you have already visited all the edges that touch the current vertex. But then the path has hit the vertex at least twice, and contains a cycle, which is impossible in a tree.</p>
<div class="Theorem">
<p><strong>Theorem.</strong> For any tree, the number of vertices <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math> is always one more than the number of edges <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>E</mi><annotation encoding="application/x-tex">E</annotation></semantics></math>. In other words, <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>E</mi><mo>+</mo><mn>1</mn><mi>.</mi></mrow><annotation encoding="application/x-tex">V = E + 1.</annotation></semantics></math></p>
</div>
<p>The key to proving this theorem is to use a technique called <strong>pruning</strong>. Since every tree must have some leaves (i.e., degree 1 vertices), you can remove a degree 1 vertex and the edge that touches it from the tree. After you do this, you will still have no cycles, and your graph will still be connected because any other two vertices will have a path connecting them. Therefore the pruned graph is still a tree, and so it still has more leaves you can prune. Each time you prune a vertex, you reduce the number of edges and vertices both by one, until you get down to a single vertex and no edges. At each step <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>âˆ’</mo><mi>E</mi></mrow><annotation encoding="application/x-tex">V-E</annotation></semantics></math> is the same, and at the end, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>âˆ’</mo><mi>E</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V-E= 1</annotation></semantics></math>, so <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>âˆ’</mo><mi>E</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V-E = 1</annotation></semantics></math> in the original tree.</p>
<p>The last helper theorem we needed was about spanning trees. A <strong>spanning tree</strong> is a subgraph of a graph that is a tree and includes all of the vertices and some of the edges from the original graph.</p>
<div class="Theorem">
<p><strong>Theorem.</strong> Every connected graph has a spanning tree.</p>
</div>
<p>This is true because if you start with a connected graph that has one or more cycles and remove one of the edges from a cycle, the new graph you get is still connected. So you can repeat the process until there are no more cycles left. When you are done, you have a connected subgraph with no cycles, i.e., a spanning tree.</p>
<p>With this last result, we were able to prove the final part of the Tree Classification Theorem: If a connected graph has exactly <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>E</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V = E+1</annotation></semantics></math> vertices, then it must be a tree. This is because a connected graph must have a spanning tree. The spanning tree has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>E</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V = E+1</annotation></semantics></math> vertices. If the original graph also has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mi>E</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">V = E+1</annotation></semantics></math> vertices. Since both the original graph and the spanning tree have the same number of vertices, we conclude that they have the same number of edges, which means that the spanning tree is the original graph. So the original graph is a tree.</p>
<p>After developing all of this theory about trees, we introduced minimal spanning trees. In a connected graph where some edges are more expensive to include than others, the <strong>minimal spanning tree</strong> is the spanning tree that would be the least expensive to build. There is a simple algorithm to find the minimum spanning tree.</p>
<div class="Theorem">
<p><strong>Kruskalâ€™s Algorithm.</strong> To find the minimal spanning tree in a connected graph, follow these steps.</p>
<ol type="1">
<li><p>Add the cheapest edge.</p></li>
<li><p>Add the second cheapest edge (it doesnâ€™t have to be next to the first edge).</p></li>
<li><p>Keep adding the cheapest edge available, as long as it doesnâ€™t make a cycle. Stop when you have a tree.<br />
</p></li>
</ol>
</div>
<p>We finished with this workshop.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/Trees.pdf">Trees</a></li>
</ul>
<h3 id="day-13-notes">Day 13 Notes</h3>
<p>Today we introduced Markov chains. We started with this example, which is from the book <em>Introduction to Finite Mathematics</em> by Kemeny, Snell, &amp; Thompson.</p>
<blockquote>
<p>The Land of Oz is blessed by many things, but not by good weather. They never have two nice days in a row. If they have a nice day, they are just as likely to have snow as rain the next day. If they have snow or rain, they have an even chance of having the same the next day. If there is change from snow or rain, only half of the time is this a change to a nice day.</p>
</blockquote>
<p>A <strong>Markov chain</strong> is a mathematical model with states and transition probabilities which only depend on the state you are currently in. The example above has three states: nice weather, rain, and snow. A Markov chain can be represented using a weighted directed graph. A <strong>directed graph</strong> is a graph where the edges have a direction (indicated by an arrow). A <strong>weighted graph</strong> is one where each edge has a number. In a Markov chain graph, the weights on the edges are the probabilities that you take that edge. Here is the graph for the weather in the Land of Oz.</p>
<center>
<img src="https://bclins.github.io/spring24/cs480/Oz.png"></img>
</center>
<p>Here is another example of a Markov chain.</p>
<blockquote>
<p>A professor tries not to be late too often. On days when he is late, he is 90% sure to arrive on time the next day. When he is on time, there is a 30% chance he will be late the next day. How often is this professor late in the long run?</p>
</blockquote>
<ol type="1">
<li><p>Draw and label a graph to represent this Markov chain.</p></li>
<li><p>If the professor is on time today, what is the probability that he will be on time the day after tomorrow?</p></li>
</ol>
<p>There is another approach to Markov chains that makes it much easier to answer questions like the last one. For a Markov chain, the <strong>transition matrix</strong> is a rectangular array of numbers where the rows represent the possible current state, the columns represent the possible states in the next round. The number in row <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> column <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> of the matrix is the probability that you will end up in state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math> if you started in state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>. For example, the transition matrix for the professor is:</p>
<center>
<table class="bordered">
<tr>
<td>
</td>
<td>
Late
</td>
<td>
On-Time
</td>
</tr>
<tr>
<td>
Late
</td>
<td>
0.1
</td>
<td>
0.9
</td>
</tr>
<tr>
<td>
On-Time
</td>
<td>
0.3
</td>
<td>
0.7
</td>
</tr>
</table>
</center>
<p>We usually donâ€™t bother writing the names of the states (as long as we can remember the order). Then we just write the transition matrix this way: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center"><mn>0.1</mn></mtd><mtd columnalign="center"><mn>0.9</mn></mtd></mtr><mtr><mtd columnalign="center"><mn>0.3</mn></mtd><mtd columnalign="center"><mn>0.7</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\begin{pmatrix} 0.1 &amp; 0.9 \\
0.3 &amp; 0.7 \end{pmatrix}</annotation></semantics></math></p>
<ol start="3" type="1">
<li>Find the transition matrix for the weather in the Land of Oz.</li>
</ol>
<p>You can model what we know about the current state using a <strong>probability vector</strong> which is a matrix with only one row and a probability for each possible state. The entries in a probability vector must add up to one. For example, here are two different probability vectors: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center"><mn>0</mn></mtd><mtd columnalign="center"><mn>1</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mtable><mtr><mtd columnalign="center"><mn>0.4</mn></mtd><mtd columnalign="center"><mn>0.6</mn></mtd></mtr></mtable><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} 0 &amp; 1 \end{pmatrix}  ~~~~~~~~ \begin{pmatrix} 0.4 &amp; 0.6 \end{pmatrix}</annotation></semantics></math> The first would represent being 100% sure that the professor is on-time. The second shows a 40% chance that the professor is late and a 60% chance that he is on-time.</p>
<p><strong>Fact.</strong> If <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math> is the transition matrix for a Markov chain and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math> is a probability vector indicated what we know about the current state, then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>Q</mi></mrow><annotation encoding="application/x-tex">vQ</annotation></semantics></math> is the probability vector for the next state.</p>
<p>In order to calculate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math> times <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>, you need to know how to <strong>multiply matrices</strong>. Here are some videos that explain how to multiply matrices: (<a href="https://youtu.be/kT4Mp9EdVqs" class="uri">https://youtu.be/kT4Mp9EdVqs</a> and <a href="https://youtu.be/OMA2Mwo0aZg" class="uri">https://youtu.be/OMA2Mwo0aZg</a>).</p>
<p>You can also raise a matrix to a power. For example, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mn>2</mn></msup><annotation encoding="application/x-tex">Q^2</annotation></semantics></math>, just means <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math> times <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mn>3</mn></msup><annotation encoding="application/x-tex">Q^3</annotation></semantics></math> is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>â‹…</mo><mi>Q</mi><mo>â‹…</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q \cdot Q \cdot Q</annotation></semantics></math>. For transition matrices, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mn>2</mn></msup><annotation encoding="application/x-tex">Q^2</annotation></semantics></math> represents how the Markov chain will change in 2 rounds and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mn>3</mn></msup><annotation encoding="application/x-tex">Q^3</annotation></semantics></math> represents how the Markov chain will change in 3 rounds. Higher powers just represent more transitions.</p>
<p>We used the <a href="https://www.desmos.com/matrix">Desmos Matrix Calculator</a> to calculate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mn>10</mn></msup><annotation encoding="application/x-tex">Q^{10}</annotation></semantics></math> for the late professor Markov chain, and we found that no matter whether the professor was late or on-time the first day, there is a roughly 25% chance he will be late 10 days later. We finished with this workshop.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/MarkovChains.pdf">Markov chains</a></li>
</ul>
<h3 id="day-14-notes">Day 14 Notes</h3>
<p>Today we continued talking about Markov chains. We started by looking at the transitions matrices for both the tardy professor example and the weather in the Land of Oz example from last time. In both cases, when you raise the matrices to larger and larger powers, the results get closer and closer to a single matrix. When that happens, we say that the matrices <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mi>k</mi></msup><annotation encoding="application/x-tex">Q^k</annotation></semantics></math> <strong>converge</strong>.</p>
<!--**Fact.** If a Markov chain has transition matrix $Q$, and $Q^k$ converges to a matrix as $k$ gets large, then the rows -->
<p>What often tends to happen is that after a large number of transitions, we get a probability vector that doesnâ€™t change. A probability vector <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math> such that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>Q</mi><mo>=</mo><mi>v</mi></mrow><annotation encoding="application/x-tex">vQ = v</annotation></semantics></math> is called a <strong>stationary distribution</strong>. It turns out that all Markov chains have a stationary distribution. If the powers of the transition matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Q</mi><mi>k</mi></msup><annotation encoding="application/x-tex">Q^k</annotation></semantics></math> converge, then each row of the matrix that they converge to is a stationary distribution for the Markov chain.</p>
<p>You can tell a lot about a Markov chain by looking at the strongly connected components of its graph.</p>
<p><strong>Definition.</strong> A directed graph is <strong>strongly connected</strong> if you can find a path from any start vertex <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> to any other end vertex <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>. A <strong>strongly connected component</strong> of a graph is a set of vertices such that (i) you can travel from any one vertex in the set to any other, and (ii) you cannot returns to the set if you leave it. Strongly connected components are also known as <strong>classes</strong>. Every vertex of the graph will always be contained in exactly one class. A class is <strong>final</strong> if there are no edges that leave the class.</p>
<center>
<img src = "https://upload.wikimedia.org/wikipedia/commons/e/e1/Scc-1.svg" width = 300></img>
</center>
<p>In the directed graph above, there is one final class <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mi>f</mi><mo>,</mo><mi>g</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{f,g\}</annotation></semantics></math> and two other non-final classes. States in a Markov chain that are not in a final class are called <strong>transitory</strong>. A state that you can enter but never leave is called <strong>absorbing</strong>. We looked at this example of a Markov chain with an absorbing state.</p>
<ol type="1">
<li><p>Suppose McDonaldâ€™s is having a Teenage Mutant Ninja Turtles special where each happy meal comes with a toy figure of one of the four ninja turtles (each equally likely). Suppose that a kid buys a happy meal every day to try to collect all four turtles.</p>
<ol type="a">
<li><p>Draw the graph for this Markov chain. Hint: The states can just be the number of different turtles the kid has collected so far.</p></li>
<li><p>What is the transition matrix for this Markov chain?</p></li>
<li><p>What is the probability of getting all four turtles if you buy 7 happy meals?</p></li>
<li><p>How many happy meals would it take for there to be at least a 90% probability of having all four turtles?</p></li>
</ol></li>
</ol>
<p>We finished with a second workshop about Markov chains.</p>
<ul>
<li><strong>Workshop:</strong> <a href="Workshops/MarkovChains2.pdf">Markov chains 2</a></li>
</ul>
<p><br> <br> <br> <br> <br> <br> <br> <br></p>
</body>
</html>
